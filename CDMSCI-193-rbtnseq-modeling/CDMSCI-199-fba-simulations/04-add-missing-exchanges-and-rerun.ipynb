{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDMSCI-199: Add Missing Exchanges and Re-run FBA\n",
    "\n",
    "## Objective\n",
    "\n",
    "Systematically add the 33 missing exchange reactions identified in Notebook 03 and re-run FBA simulations to quantify improvement.\n",
    "\n",
    "## Background\n",
    "\n",
    "From Notebooks 02 and 03, we identified:\n",
    "- 571 False Negatives (all with biomass_flux = 0)\n",
    "- 33 missing exchange reactions across 23 organisms for:\n",
    "  - Fe2+ (cpd10515): 14 organisms missing\n",
    "  - Ni2+ (cpd00244): 14 organisms missing\n",
    "  - Molybdate (cpd11574): 5 organisms missing\n",
    "\n",
    "Missing exchanges correlate with higher FN rates:\n",
    "- Fe2+: +12.5% higher FN rate\n",
    "- Molybdate: +19.2% higher FN rate\n",
    "- Ni2+: +5.0% higher FN rate\n",
    "\n",
    "## Approach\n",
    "\n",
    "1. Load missing exchanges list\n",
    "2. For each affected organism:\n",
    "   - Load gap-filled model\n",
    "   - Add missing exchange reaction(s)\n",
    "   - Save corrected model\n",
    "3. Re-run FBA simulations for ALL organism-carbon combinations (to avoid selective bias)\n",
    "4. Compare before/after performance\n",
    "\n",
    "## Expected Outcomes\n",
    "\n",
    "- Reduce FN count from 571 to ~230-285\n",
    "- Improve recall from 43% to ~65-75%\n",
    "- Improve accuracy from 63% to ~78-82%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COBRApy version: 0.29.1\n",
      "Pandas version: 2.2.2\n",
      "NumPy version: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cobra\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"COBRApy version: {cobra.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Missing Exchanges Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing exchanges: 33\n",
      "\n",
      "Breakdown by compound:\n",
      "compound_name\n",
      "Fe2+         14\n",
      "Molybdate     5\n",
      "Ni2+         14\n",
      "Name: orgId, dtype: int64\n",
      "\n",
      "Unique organisms affected: 28\n",
      "\n",
      "First 10 missing exchanges:\n",
      "                 orgId                                organism compound_id  \\\n",
      "0                 ANA3                    Shewanella sp. ANA-3    cpd00244   \n",
      "1                BFirm          Burkholderia phytofirmans PsJN    cpd10515   \n",
      "2               Bifido           Bifidobacterium breve UCC2003    cpd10515   \n",
      "3               Bifido           Bifidobacterium breve UCC2003    cpd11574   \n",
      "4                Brev2    Brevundimonas sp. GW460-12-10-14-LB2    cpd00244   \n",
      "5                Brev2    Brevundimonas sp. GW460-12-10-14-LB2    cpd11574   \n",
      "6               Btheta   Bacteroides thetaiotaomicron VPI-5482    cpd00244   \n",
      "7               Btheta   Bacteroides thetaiotaomicron VPI-5482    cpd11574   \n",
      "8              Burk376  Paraburkholderia bryophila 376MFSha3.1    cpd10515   \n",
      "9  Burkholderia_OAS925        Paraburkholderia graminis OAS925    cpd10515   \n",
      "\n",
      "  compound_name  \n",
      "0          Ni2+  \n",
      "1          Fe2+  \n",
      "2          Fe2+  \n",
      "3     Molybdate  \n",
      "4          Ni2+  \n",
      "5     Molybdate  \n",
      "6          Ni2+  \n",
      "7     Molybdate  \n",
      "8          Fe2+  \n",
      "9          Fe2+  \n"
     ]
    }
   ],
   "source": [
    "# Load missing exchanges details\n",
    "missing_exchanges = pd.read_csv('results/missing_exchanges_details.csv')\n",
    "\n",
    "print(f\"Missing exchanges: {len(missing_exchanges)}\")\n",
    "print(f\"\\nBreakdown by compound:\")\n",
    "print(missing_exchanges.groupby('compound_name')['orgId'].count())\n",
    "print(f\"\\nUnique organisms affected: {missing_exchanges['orgId'].nunique()}\")\n",
    "print(f\"\\nFirst 10 missing exchanges:\")\n",
    "print(missing_exchanges.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Exchange Reaction IDs\n",
    "\n",
    "ModelSEED exchange reactions follow the pattern: `EX_{compound_id}_e0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exchange reactions to add:\n",
      "  Fe2+ (cpd10515): EX_cpd10515_e0\n",
      "  Ni2+ (cpd00244): EX_cpd00244_e0\n",
      "  Molybdate (cpd11574): EX_cpd11574_e0\n"
     ]
    }
   ],
   "source": [
    "# Define exchange reaction IDs for each compound\n",
    "exchange_reaction_ids = {\n",
    "    'cpd10515': 'EX_cpd10515_e0',  # Fe2+\n",
    "    'cpd00244': 'EX_cpd00244_e0',  # Ni2+\n",
    "    'cpd11574': 'EX_cpd11574_e0',  # Molybdate\n",
    "}\n",
    "\n",
    "# Map compound IDs to names for reporting\n",
    "compound_names = {\n",
    "    'cpd10515': 'Fe2+',\n",
    "    'cpd00244': 'Ni2+',\n",
    "    'cpd11574': 'Molybdate',\n",
    "}\n",
    "\n",
    "print(\"Exchange reactions to add:\")\n",
    "for cpd_id, rxn_id in exchange_reaction_ids.items():\n",
    "    name = compound_names[cpd_id]\n",
    "    print(f\"  {name} ({cpd_id}): {rxn_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Organism Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total organisms: 44\n",
      "\n",
      "Columns: ['orgId', 'organism', 'genome_id']\n",
      "\n",
      "First 5 organisms:\n",
      "             orgId                               organism        genome_id\n",
      "0  acidovorax_3H11              Acidovorax sp. GW101-3H11  acidovorax_3H11\n",
      "1           azobra          Azospirillum brasilense Sp245           azobra\n",
      "2           Btheta  Bacteroides thetaiotaomicron VPI-5482           Btheta\n",
      "3           Bifido          Bifidobacterium breve UCC2003           Bifido\n",
      "4            Brev2   Brevundimonas sp. GW460-12-10-14-LB2            Brev2\n"
     ]
    }
   ],
   "source": [
    "# Load organism metadata\n",
    "organism_metadata = pd.read_csv('results/organism_metadata.csv')\n",
    "\n",
    "print(f\"Total organisms: {len(organism_metadata)}\")\n",
    "print(f\"\\nColumns: {list(organism_metadata.columns)}\")\n",
    "print(f\"\\nFirst 5 organisms:\")\n",
    "print(organism_metadata[['orgId', 'organism', 'genome_id']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models with Missing Exchanges Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models with missing exchanges added will be saved to: models_missing_exchanges\n"
     ]
    }
   ],
   "source": [
    "# Create directory for models with missing exchanges added\n",
    "models_with_exchanges_dir = Path('models_missing_exchanges')\n",
    "models_with_exchanges_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Models with missing exchanges added will be saved to: {models_with_exchanges_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Add Exchange Reaction\n",
    "\n",
    "Add a new exchange reaction to a model if it doesn't already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function defined: add_exchange_reaction()\n"
     ]
    }
   ],
   "source": [
    "def add_exchange_reaction(model, compound_id, exchange_rxn_id, compound_name):\n",
    "    \"\"\"\n",
    "    Add an exchange reaction to a COBRA model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : cobra.Model\n",
    "        The model to modify\n",
    "    compound_id : str\n",
    "        ModelSEED compound ID (e.g., 'cpd10515')\n",
    "    exchange_rxn_id : str\n",
    "        Exchange reaction ID (e.g., 'EX_cpd10515_e0')\n",
    "    compound_name : str\n",
    "        Human-readable name (e.g., 'Fe2+')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if added, False if already exists\n",
    "    \"\"\"\n",
    "    # Check if exchange already exists\n",
    "    if exchange_rxn_id in model.reactions:\n",
    "        return False\n",
    "    \n",
    "    # Find the metabolite (usually in extracellular compartment _e0)\n",
    "    metabolite_id = f\"{compound_id}_e0\"\n",
    "    \n",
    "    if metabolite_id not in model.metabolites:\n",
    "        # Metabolite doesn't exist, create it\n",
    "        met = cobra.Metabolite(\n",
    "            id=metabolite_id,\n",
    "            name=compound_name,\n",
    "            compartment='e0'\n",
    "        )\n",
    "        # Note: COBRA will add the metabolite when we add the reaction\n",
    "    else:\n",
    "        met = model.metabolites.get_by_id(metabolite_id)\n",
    "    \n",
    "    # Create exchange reaction\n",
    "    # Exchange reactions allow uptake and secretion: metabolite_e0 <=>\n",
    "    exchange_rxn = cobra.Reaction(\n",
    "        id=exchange_rxn_id,\n",
    "        name=f\"{compound_name} exchange\",\n",
    "        lower_bound=-100.0,  # Allow uptake up to 100 mmol/gDW/h\n",
    "        upper_bound=100.0     # Allow secretion up to 100 mmol/gDW/h\n",
    "    )\n",
    "    \n",
    "    # Add metabolite to reaction (exchange reactions have single metabolite)\n",
    "    exchange_rxn.add_metabolites({met: -1.0})  # Negative for uptake convention\n",
    "    \n",
    "    # Add reaction to model\n",
    "    model.add_reactions([exchange_rxn])\n",
    "    \n",
    "    return True\n",
    "\n",
    "print(\"Function defined: add_exchange_reaction()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Missing Exchanges to Models\n",
    "\n",
    "Process each organism and add missing exchange reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 28 organisms...\n",
      "================================================================================\n",
      "\n",
      "Shewanella sp. ANA-3 (ANA3):\n",
      "  + Added: EX_cpd00244_e0 (Ni2+)\n",
      "  Reactions: 1348 → 1349 (+1)\n",
      "  Saved to: ANA3_gapfilled_corrected.json\n",
      "\n",
      "Burkholderia phytofirmans PsJN (BFirm):\n",
      "  + Added: EX_cpd10515_e0 (Fe2+)\n",
      "  Reactions: 1568 → 1569 (+1)\n",
      "  Saved to: BFirm_gapfilled_corrected.json\n",
      "\n",
      "Bifidobacterium breve UCC2003 (Bifido):\n"
     ]
    }
   ],
   "source": [
    "# Track corrections\n",
    "correction_log = []\n",
    "\n",
    "# Get unique organisms that need corrections\n",
    "organisms_to_correct = missing_exchanges['orgId'].unique()\n",
    "\n",
    "print(f\"Processing {len(organisms_to_correct)} organisms...\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for org_id in organisms_to_correct:\n",
    "    # Get organism info\n",
    "    org_info = organism_metadata[organism_metadata['orgId'] == org_id]\n",
    "    if len(org_info) == 0:\n",
    "        print(f\"WARNING: Organism {org_id} not found in metadata\")\n",
    "        continue\n",
    "    \n",
    "    organism_name = org_info.iloc[0]['organism']\n",
    "    genome_id = org_info.iloc[0]['genome_id']\n",
    "    \n",
    "    # Load gap-filled model\n",
    "    model_path = Path(f\"../CDMSCI-198-build-models/models/{genome_id}_gapfilled.json\")\n",
    "    \n",
    "    if not model_path.exists():\n",
    "        print(f\"WARNING: Model not found: {model_path}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{organism_name} ({org_id}):\")\n",
    "    \n",
    "    # Load model\n",
    "    model = cobra.io.load_json_model(str(model_path))\n",
    "    original_num_reactions = len(model.reactions)\n",
    "    \n",
    "    # Get missing compounds for this organism\n",
    "    missing_for_org = missing_exchanges[missing_exchanges['orgId'] == org_id]\n",
    "    \n",
    "    exchanges_added = []\n",
    "    \n",
    "    # Add each missing exchange\n",
    "    for idx, row in missing_for_org.iterrows():\n",
    "        cpd_id = row['compound_id']\n",
    "        cpd_name = row['compound_name']\n",
    "        exchange_rxn_id = exchange_reaction_ids[cpd_id]\n",
    "        \n",
    "        added = add_exchange_reaction(model, cpd_id, exchange_rxn_id, cpd_name)\n",
    "        \n",
    "        if added:\n",
    "            exchanges_added.append(cpd_name)\n",
    "            print(f\"  + Added: {exchange_rxn_id} ({cpd_name})\")\n",
    "        else:\n",
    "            print(f\"  - Already exists: {exchange_rxn_id} ({cpd_name})\")\n",
    "    \n",
    "    # Save corrected model\n",
    "    corrected_model_path = models_with_exchanges_dir / f\"{genome_id}_gapfilled_corrected.json\"\n",
    "    cobra.io.save_json_model(model, str(corrected_model_path))\n",
    "    \n",
    "    new_num_reactions = len(model.reactions)\n",
    "    \n",
    "    print(f\"  Reactions: {original_num_reactions} → {new_num_reactions} (+{new_num_reactions - original_num_reactions})\")\n",
    "    print(f\"  Saved to: {corrected_model_path.name}\")\n",
    "    \n",
    "    # Log correction\n",
    "    correction_log.append({\n",
    "        'orgId': org_id,\n",
    "        'organism': organism_name,\n",
    "        'genome_id': genome_id,\n",
    "        'exchanges_added': ', '.join(exchanges_added),\n",
    "        'num_exchanges_added': len(exchanges_added),\n",
    "        'original_reactions': original_num_reactions,\n",
    "        'corrected_reactions': new_num_reactions,\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"\\nCompleted! Corrected {len(correction_log)} models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Correction Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save correction log\n",
    "correction_df = pd.DataFrame(correction_log)\n",
    "correction_df.to_csv('results/model_corrections_log.csv', index=False)\n",
    "\n",
    "print(\"Model correction log:\")\n",
    "print(correction_df.to_string(index=False))\n",
    "print(f\"\\nSaved to: results/model_corrections_log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run FBA Simulations\n",
    "\n",
    "Run FBA for all organism-carbon combinations using models with missing exchanges added.\n",
    "\n",
    "**Important**: We re-run ALL simulations (not just affected ones) to avoid selective bias in the comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carbon sources to simulate: 121\n",
      "Organisms to simulate: 44\n",
      "Total simulations: 5,324\n"
     ]
    }
   ],
   "source": [
    "# Load simulatable sources (already filtered in Notebook 01)\n",
    "simulatable = pd.read_csv('results/simulatable_carbon_sources.csv')\n",
    "\n",
    "print(f\"Carbon sources to simulate: {len(simulatable)}\")\n",
    "print(f\"Organisms to simulate: {len(organism_metadata)}\")\n",
    "print(f\"Total simulations: {len(simulatable) * len(organism_metadata):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Simulations with Models with Missing Exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting FBA simulations with CORRECTED models...\n",
      "Total simulations: 5,324\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'carbon_source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'carbon_source'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Run FBA for each carbon source\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cs_idx, cs_row \u001b[38;5;129;01min\u001b[39;00m simulatable\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 41\u001b[0m     carbon_source \u001b[38;5;241m=\u001b[39m \u001b[43mcs_row\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcarbon_source\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     42\u001b[0m     media_filename \u001b[38;5;241m=\u001b[39m cs_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedia_file\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     43\u001b[0m     media_path \u001b[38;5;241m=\u001b[39m media_dir \u001b[38;5;241m/\u001b[39m media_filename\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'carbon_source'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from cobra.exceptions import OptimizationError\n",
    "\n",
    "# Storage for results\n",
    "results_corrected = []\n",
    "\n",
    "# Media directory\n",
    "media_dir = Path('../CDMSCI-197-media-formulations/media')\n",
    "\n",
    "# Track progress\n",
    "total_sims = len(organism_metadata) * len(simulatable)\n",
    "start_time = time.time()\n",
    "\n",
    "print(f\"Starting FBA simulations with CORRECTED models...\")\n",
    "print(f\"Total simulations: {total_sims:,}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sim_count = 0\n",
    "\n",
    "for org_idx, org_row in organism_metadata.iterrows():\n",
    "    org_id = org_row['orgId']\n",
    "    organism = org_row['organism']\n",
    "    genome_id = org_row['genome_id']\n",
    "    \n",
    "    # Load corrected model if it exists, otherwise use original\n",
    "    corrected_model_path = models_with_exchanges_dir / f\"{genome_id}_gapfilled_corrected.json\"\n",
    "    original_model_path = Path(f\"../CDMSCI-198-build-models/models/{genome_id}_gapfilled.json\")\n",
    "    \n",
    "    if corrected_model_path.exists():\n",
    "        model_path = corrected_model_path\n",
    "        model_type = 'corrected'\n",
    "    else:\n",
    "        model_path = original_model_path\n",
    "        model_type = 'original'\n",
    "    \n",
    "    # Load model\n",
    "    model = cobra.io.load_json_model(str(model_path))\n",
    "    \n",
    "    # Run FBA for each carbon source\n",
    "    for cs_idx, cs_row in simulatable.iterrows():\n",
    "        carbon_source = cs_row['carbon_source']\n",
    "        media_filename = cs_row['media_file']\n",
    "        media_path = media_dir / media_filename\n",
    "        \n",
    "        # Load media\n",
    "        with open(media_path, 'r') as f:\n",
    "            media = json.load(f)\n",
    "        \n",
    "        # Apply media to model\n",
    "        for rxn_id, bounds in media.items():\n",
    "            if rxn_id in model.reactions:\n",
    "                rxn = model.reactions.get_by_id(rxn_id)\n",
    "                rxn.lower_bound = bounds[0]\n",
    "                rxn.upper_bound = bounds[1]\n",
    "        \n",
    "        # Run FBA\n",
    "        try:\n",
    "            solution = model.optimize()\n",
    "            biomass_flux = solution.objective_value\n",
    "            status = solution.status\n",
    "        except OptimizationError as e:\n",
    "            biomass_flux = 0.0\n",
    "            status = 'failed'\n",
    "        \n",
    "        # Prediction (threshold 0.001)\n",
    "        prediction = 1 if biomass_flux > 0.001 else 0\n",
    "        \n",
    "        # Store result\n",
    "        results_corrected.append({\n",
    "            'organism': organism,\n",
    "            'orgId': org_id,\n",
    "            'carbon_source': carbon_source,\n",
    "            'media_filename': media_filename,\n",
    "            'biomass_flux': biomass_flux,\n",
    "            'status': status,\n",
    "            'prediction': prediction,\n",
    "            'model_type': model_type,\n",
    "        })\n",
    "        \n",
    "        sim_count += 1\n",
    "    \n",
    "    # Progress update every 5 organisms\n",
    "    if (org_idx + 1) % 5 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        rate = sim_count / elapsed\n",
    "        remaining = (total_sims - sim_count) / rate\n",
    "        print(f\"Progress: {sim_count:,}/{total_sims:,} ({100*sim_count/total_sims:.1f}%) - \"\n",
    "              f\"Elapsed: {elapsed/60:.1f}min, Remaining: {remaining/60:.1f}min\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Simulations complete!\")\n",
    "print(f\"Total time: {elapsed_time/60:.1f} minutes ({elapsed_time/3600:.2f} hours)\")\n",
    "print(f\"Simulations: {len(results_corrected):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Corrected Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and save\n",
    "results_corrected_df = pd.DataFrame(results_corrected)\n",
    "results_corrected_df.to_csv('results/fba_simulation_results_corrected.csv', index=False)\n",
    "\n",
    "print(f\"Saved corrected results: results/fba_simulation_results_corrected.csv\")\n",
    "print(f\"\\nResults shape: {results_corrected_df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(results_corrected_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Before vs After: Overall Metrics\n",
    "\n",
    "Calculate confusion matrix and metrics for models with missing exchanges added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load experimental data\n",
    "experimental_data = pd.read_csv('../CDMSCI-196-carbon-sources/results/combined_growth_matrix_filtered.csv', index_col=0)\n",
    "\n",
    "# Convert to binary\n",
    "experimental_binary = experimental_data.replace({'Growth': 1, 'No Growth': 0})\n",
    "\n",
    "print(f\"Experimental data shape: {experimental_binary.shape}\")\n",
    "print(f\"Valid experimental data points: {experimental_binary.notna().sum().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corrected prediction matrix\n",
    "fba_corrected_matrix = results_corrected_df.pivot(\n",
    "    index='carbon_source', \n",
    "    columns='organism', \n",
    "    values='prediction'\n",
    ")\n",
    "\n",
    "print(f\"Corrected prediction matrix shape: {fba_corrected_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align matrices\n",
    "common_sources = experimental_binary.index.intersection(fba_corrected_matrix.index)\n",
    "common_organisms = experimental_binary.columns.intersection(fba_corrected_matrix.columns)\n",
    "\n",
    "exp_aligned = experimental_binary.loc[common_sources, common_organisms]\n",
    "fba_corrected_aligned = fba_corrected_matrix.loc[common_sources, common_organisms]\n",
    "\n",
    "print(f\"Aligned shape: {exp_aligned.shape}\")\n",
    "print(f\"Valid comparisons: {exp_aligned.notna().sum().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract valid comparison data for models with missing exchanges added\n",
    "exp_flat = exp_aligned.values.flatten()\n",
    "fba_corrected_flat = fba_corrected_aligned.values.flatten()\n",
    "\n",
    "valid_mask = ~np.isnan(exp_flat)\n",
    "\n",
    "y_true_corrected = exp_flat[valid_mask].astype(int)\n",
    "y_pred_corrected = fba_corrected_flat[valid_mask].astype(int)\n",
    "\n",
    "print(f\"Valid comparisons: {len(y_true_corrected):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate corrected metrics\n",
    "cm_corrected = confusion_matrix(y_true_corrected, y_pred_corrected)\n",
    "tn_c, fp_c, fn_c, tp_c = cm_corrected.ravel()\n",
    "\n",
    "accuracy_c = accuracy_score(y_true_corrected, y_pred_corrected)\n",
    "precision_c = precision_score(y_true_corrected, y_pred_corrected, zero_division=0)\n",
    "recall_c = recall_score(y_true_corrected, y_pred_corrected, zero_division=0)\n",
    "f1_c = f1_score(y_true_corrected, y_pred_corrected, zero_division=0)\n",
    "specificity_c = tn_c / (tn_c + fp_c) if (tn_c + fp_c) > 0 else 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CORRECTED MODEL PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(f\"                      Predicted\")\n",
    "print(f\"                 No Growth    Growth\")\n",
    "print(f\"Experimental\")\n",
    "print(f\"  No Growth      {tn_c:6d}      {fp_c:6d}\")\n",
    "print(f\"  Growth         {fn_c:6d}      {tp_c:6d}\")\n",
    "print()\n",
    "print(f\"True Negatives (TN):  {tn_c:,}\")\n",
    "print(f\"False Positives (FP): {fp_c:,}\")\n",
    "print(f\"False Negatives (FN): {fn_c:,}\")\n",
    "print(f\"True Positives (TP):  {tp_c:,}\")\n",
    "print()\n",
    "print(f\"Accuracy:    {accuracy_c:.4f} ({accuracy_c*100:.2f}%)\")\n",
    "print(f\"Precision:   {precision_c:.4f} ({precision_c*100:.2f}%)\")\n",
    "print(f\"Recall:      {recall_c:.4f} ({recall_c*100:.2f}%)\")\n",
    "print(f\"F1-Score:    {f1_c:.4f}\")\n",
    "print(f\"Specificity: {specificity_c:.4f} ({specificity_c*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Before vs After\n",
    "\n",
    "Load original results and compare side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original metrics\n",
    "with open('results/classification_metrics.json', 'r') as f:\n",
    "    original_metrics = json.load(f)\n",
    "\n",
    "# Create comparison\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': ['True Positives', 'True Negatives', 'False Positives', 'False Negatives', \n",
    "               'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Specificity'],\n",
    "    'Original': [\n",
    "        original_metrics['true_positives'],\n",
    "        original_metrics['true_negatives'],\n",
    "        original_metrics['false_positives'],\n",
    "        original_metrics['false_negatives'],\n",
    "        f\"{original_metrics['accuracy']:.4f}\",\n",
    "        f\"{original_metrics['precision']:.4f}\",\n",
    "        f\"{original_metrics['recall']:.4f}\",\n",
    "        f\"{original_metrics['f1_score']:.4f}\",\n",
    "        f\"{original_metrics['specificity']:.4f}\",\n",
    "    ],\n",
    "    'Corrected': [\n",
    "        tp_c,\n",
    "        tn_c,\n",
    "        fp_c,\n",
    "        fn_c,\n",
    "        f\"{accuracy_c:.4f}\",\n",
    "        f\"{precision_c:.4f}\",\n",
    "        f\"{recall_c:.4f}\",\n",
    "        f\"{f1_c:.4f}\",\n",
    "        f\"{specificity_c:.4f}\",\n",
    "    ],\n",
    "})\n",
    "\n",
    "# Calculate changes\n",
    "comparison['Change'] = [\n",
    "    f\"{tp_c - original_metrics['true_positives']:+d}\",\n",
    "    f\"{tn_c - original_metrics['true_negatives']:+d}\",\n",
    "    f\"{fp_c - original_metrics['false_positives']:+d}\",\n",
    "    f\"{fn_c - original_metrics['false_negatives']:+d}\",\n",
    "    f\"{accuracy_c - original_metrics['accuracy']:+.4f}\",\n",
    "    f\"{precision_c - original_metrics['precision']:+.4f}\",\n",
    "    f\"{recall_c - original_metrics['recall']:+.4f}\",\n",
    "    f\"{f1_c - original_metrics['f1_score']:+.4f}\",\n",
    "    f\"{specificity_c - original_metrics['specificity']:+.4f}\",\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"BEFORE vs AFTER COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(comparison.to_string(index=False))\n",
    "print()\n",
    "\n",
    "# Calculate improvement percentages\n",
    "fn_reduction = original_metrics['false_negatives'] - fn_c\n",
    "fn_reduction_pct = 100 * fn_reduction / original_metrics['false_negatives']\n",
    "recall_improvement = recall_c - original_metrics['recall']\n",
    "recall_improvement_pct = 100 * recall_improvement / original_metrics['recall']\n",
    "accuracy_improvement = accuracy_c - original_metrics['accuracy']\n",
    "accuracy_improvement_pct = 100 * accuracy_improvement / original_metrics['accuracy']\n",
    "\n",
    "print(\"KEY IMPROVEMENTS:\")\n",
    "print(f\"  False Negatives: {original_metrics['false_negatives']} → {fn_c} ({fn_reduction:+d}, {fn_reduction_pct:+.1f}%)\")\n",
    "print(f\"  Recall: {original_metrics['recall']:.4f} → {recall_c:.4f} ({recall_improvement:+.4f}, {recall_improvement_pct:+.1f}%)\")\n",
    "print(f\"  Accuracy: {original_metrics['accuracy']:.4f} → {accuracy_c:.4f} ({accuracy_improvement:+.4f}, {accuracy_improvement_pct:+.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Corrected Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save corrected metrics\n",
    "corrected_metrics = {\n",
    "    'total_comparisons': int(len(y_true_corrected)),\n",
    "    'true_positives': int(tp_c),\n",
    "    'true_negatives': int(tn_c),\n",
    "    'false_positives': int(fp_c),\n",
    "    'false_negatives': int(fn_c),\n",
    "    'accuracy': float(accuracy_c),\n",
    "    'precision': float(precision_c),\n",
    "    'recall': float(recall_c),\n",
    "    'f1_score': float(f1_c),\n",
    "    'specificity': float(specificity_c)\n",
    "}\n",
    "\n",
    "with open('results/classification_metrics_corrected.json', 'w') as f:\n",
    "    json.dump(corrected_metrics, f, indent=2)\n",
    "\n",
    "print(f\"Saved corrected metrics to: results/classification_metrics_corrected.json\")\n",
    "\n",
    "# Save comparison\n",
    "comparison.to_csv('results/before_after_comparison.csv', index=False)\n",
    "print(f\"Saved comparison to: results/before_after_comparison.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Organism Improvement Analysis\n",
    "\n",
    "Analyze which organisms improved the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate per-organism metrics for models with missing exchanges added\n",
    "organism_metrics_corrected = []\n",
    "\n",
    "for organism in common_organisms:\n",
    "    exp_org = exp_aligned[organism]\n",
    "    fba_org = fba_corrected_aligned[organism]\n",
    "    \n",
    "    valid_mask = exp_org.notna()\n",
    "    y_true_org = exp_org[valid_mask].astype(int)\n",
    "    y_pred_org = fba_org[valid_mask].astype(int)\n",
    "    \n",
    "    if len(y_true_org) == 0:\n",
    "        continue\n",
    "    \n",
    "    cm_org = confusion_matrix(y_true_org, y_pred_org, labels=[0, 1])\n",
    "    tn_o, fp_o, fn_o, tp_o = cm_org.ravel()\n",
    "    \n",
    "    accuracy_org = accuracy_score(y_true_org, y_pred_org)\n",
    "    recall_org = recall_score(y_true_org, y_pred_org, zero_division=0)\n",
    "    \n",
    "    organism_metrics_corrected.append({\n",
    "        'organism': organism,\n",
    "        'n_comparisons': len(y_true_org),\n",
    "        'TP': int(tp_o),\n",
    "        'TN': int(tn_o),\n",
    "        'FP': int(fp_o),\n",
    "        'FN': int(fn_o),\n",
    "        'accuracy': accuracy_org,\n",
    "        'recall': recall_org,\n",
    "    })\n",
    "\n",
    "organism_corrected_df = pd.DataFrame(organism_metrics_corrected)\n",
    "\n",
    "# Load original organism metrics\n",
    "organism_original_df = pd.read_csv('results/per_organism_accuracy.csv')\n",
    "\n",
    "# Merge and compare\n",
    "organism_comparison = organism_original_df[['organism', 'accuracy', 'recall', 'FN']].merge(\n",
    "    organism_corrected_df[['organism', 'accuracy', 'recall', 'FN']],\n",
    "    on='organism',\n",
    "    suffixes=('_original', '_corrected')\n",
    ")\n",
    "\n",
    "# Calculate improvements\n",
    "organism_comparison['accuracy_change'] = organism_comparison['accuracy_corrected'] - organism_comparison['accuracy_original']\n",
    "organism_comparison['recall_change'] = organism_comparison['recall_corrected'] - organism_comparison['recall_original']\n",
    "organism_comparison['FN_change'] = organism_comparison['FN_corrected'] - organism_comparison['FN_original']\n",
    "\n",
    "# Sort by accuracy improvement\n",
    "organism_comparison = organism_comparison.sort_values('accuracy_change', ascending=False)\n",
    "\n",
    "print(\"TOP 10 MOST IMPROVED ORGANISMS:\")\n",
    "print(organism_comparison.head(10)[['organism', 'accuracy_original', 'accuracy_corrected', 'accuracy_change', 'FN_original', 'FN_corrected', 'FN_change']].to_string(index=False))\n",
    "\n",
    "# Save\n",
    "organism_comparison.to_csv('results/per_organism_improvement.csv', index=False)\n",
    "print(f\"\\nSaved to: results/per_organism_improvement.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CDMSCI-199 NOTEBOOK 04: MODEL CORRECTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"MODELS CORRECTED:\")\n",
    "print(f\"  Organisms: {len(correction_df)}\")\n",
    "print(f\"  Total exchanges added: {correction_df['num_exchanges_added'].sum()}\")\n",
    "print()\n",
    "print(\"OVERALL IMPROVEMENT:\")\n",
    "print(f\"  Accuracy: {original_metrics['accuracy']:.4f} → {accuracy_c:.4f} ({accuracy_improvement:+.4f}, {accuracy_improvement_pct:+.1f}%)\")\n",
    "print(f\"  Recall: {original_metrics['recall']:.4f} → {recall_c:.4f} ({recall_improvement:+.4f}, {recall_improvement_pct:+.1f}%)\")\n",
    "print(f\"  False Negatives: {original_metrics['false_negatives']} → {fn_c} ({fn_reduction:+d}, {fn_reduction_pct:+.1f}%)\")\n",
    "print()\n",
    "print(\"MOST IMPROVED ORGANISMS:\")\n",
    "for idx, row in organism_comparison.head(5).iterrows():\n",
    "    print(f\"  {row['organism']}:\")\n",
    "    print(f\"    Accuracy: {row['accuracy_original']:.3f} → {row['accuracy_corrected']:.3f} ({row['accuracy_change']:+.3f})\")\n",
    "    print(f\"    FN: {row['FN_original']} → {row['FN_corrected']} ({row['FN_change']:+d})\")\n",
    "print()\n",
    "print(\"FILES GENERATED:\")\n",
    "print(\"  1. models_missing_exchanges/ - Directory with 23 models with missing exchanges added\")\n",
    "print(\"  2. results/model_corrections_log.csv - Log of corrections made\")\n",
    "print(\"  3. results/fba_simulation_results_corrected.csv - New simulation results\")\n",
    "print(\"  4. results/classification_metrics_corrected.json - New metrics\")\n",
    "print(\"  5. results/before_after_comparison.csv - Side-by-side comparison\")\n",
    "print(\"  6. results/per_organism_improvement.csv - Per-organism changes\")\n",
    "print()\n",
    "print(\"Analysis complete! Ready for Notebook 05 (comprehensive final analysis).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
